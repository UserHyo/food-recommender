import pickle
import joblib
import pandas as pd
import numpy as np
import streamlit as st
import requests
from datetime import datetime

@st.cache_resource
def load_preprocessors():
    with open("preprocessors/streamlit_label_encoders.pkl", "rb") as f:
        encoders = pickle.load(f)
    with open("preprocessors/streamlit_scalers.pkl", "rb") as f:
        scalers = pickle.load(f)
    return encoders, scalers

@st.cache_resource
def load_models():
    model_names = ["BrunchSalad", "Noodles", "RiceDishes", "SideDish", "SoupStew", "StirFryGrill"]
    models = {}
    for name in model_names:
        models[name] = joblib.load(f"models/{name}.pkl")
    return models

@st.cache_data
def load_food_data():
    return pd.read_csv("cleaned_food.csv")


# ì§€ì—­ëª… â†’ ìœ„ë„/ê²½ë„
region_coords = {
    "ì„œìš¸": (37.5665, 126.9780),
    "ë¶€ì‚°": (35.1796, 129.0756),
    "ëŒ€ì „": (36.3504, 127.3845),
    "ê´‘ì£¼": (35.1595, 126.8526),
    "ì œì£¼": (33.4996, 126.5312),
    "ê°•ë¦‰": (37.7519, 128.8761)
}

# ê²©ì ë³€í™˜ í•¨ìˆ˜
def dfs_xy_conv(lat, lon):
    import math
    RE = 6371.00877
    GRID = 5.0
    SLAT1, SLAT2 = 30.0, 60.0
    OLON, OLAT = 126.0, 38.0
    XO, YO = 43, 136
    DEGRAD = math.pi / 180.0
    re = RE / GRID
    slat1 = SLAT1 * DEGRAD
    slat2 = SLAT2 * DEGRAD
    olon = OLON * DEGRAD
    olat = OLAT * DEGRAD
    sn = math.log(math.cos(slat1) / math.cos(slat2)) / \
         math.log(math.tan(math.pi * 0.25 + slat2 * 0.5) /
                  math.tan(math.pi * 0.25 + slat1 * 0.5))
    sf = (math.tan(math.pi * 0.25 + slat1 * 0.5) ** sn) * math.cos(slat1) / sn
    ro = re * sf / (math.tan(math.pi * 0.25 + olat * 0.5) ** sn)
    ra = re * sf / (math.tan(math.pi * 0.25 + lat * DEGRAD * 0.5) ** sn)
    theta = lon * DEGRAD - olon
    theta *= sn
    x = ra * math.sin(theta) + XO
    y = ro - ra * math.cos(theta) + YO
    return int(x + 1.5), int(y + 1.5)

API_KEY = "DEaTeAeMY+/ZCys9LTGzBk/MnsJg8VJSGr7h5yrG94i8/FSzVyxUgMsVAM1E3B4XEmYhiTRt5a/fxW+ODvMJ6w=="

def get_weather_data(region_name):
    lat, lon = region_coords[region_name]
    x, y = dfs_xy_conv(lat, lon)
    base_date = datetime.today().strftime('%Y%m%d')
    base_time = "0500"

    url = (
        f"https://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst"
        f"?serviceKey={API_KEY}&pageNo=1&numOfRows=1000&dataType=JSON"
        f"&base_date={base_date}&base_time={base_time}&nx={x}&ny={y}"
    )

    res = requests.get(url)
    items = res.json().get("response", {}).get("body", {}).get("items", {}).get("item", [])

    result = {"TA_AVG": None, "HM_AVG": None, "WS_AVG": None, "RN_DAY": 0.0}
    for item in items:
        cat = item["category"]
        val = item["fcstValue"]
        if cat == "TMP":
            result["TA_AVG"] = float(val)
        elif cat == "REH":
            result["HM_AVG"] = float(val)
        elif cat == "WSD":
            result["WS_AVG"] = float(val)
        elif cat == "PCP":
            result["RN_DAY"] = 0.0 if val == "ê°•ìˆ˜ì—†ìŒ" else float(val.replace("mm", "").strip())
    return result

def preprocess_input(gender, age_group, region, weather, encoders, scalers):
    gender_enc = encoders["gender"].transform([gender])[0]
    age_enc = encoders["age_group"].transform([age_group])[0]
    region_enc = encoders["region"].transform([region])[0]

    ta = scalers["TA_AVG"].transform([[weather["TA_AVG"]]])[0][0]
    hm = scalers["HM_AVG"].transform([[weather["HM_AVG"]]])[0][0]
    ws = scalers["WS_AVG"].transform([[weather["WS_AVG"]]])[0][0]
    rn = scalers["RN_DAY"].transform([[weather["RN_DAY"]]])[0][0]

    today = datetime.today()
    return pd.DataFrame([{
        "Gender": gender_enc,
        "Age_Group": age_enc,
        "Region": region_enc,
        "TA_AVG": ta,
        "HM_AVG": hm,
        "WS_AVG": ws,
        "RN_DAY": rn,
        "Month_sin": np.sin(2 * np.pi * today.month / 12),
        "Month_cos": np.cos(2 * np.pi * today.month / 12),
        "Day_sin": np.sin(2 * np.pi * today.day / 31),
        "Day_cos": np.cos(2 * np.pi * today.day / 31),
        "is_weekend": int(today.weekday() >= 5)
    }])

st.title("ğŸ± ë‚ ì”¨ ê¸°ë°˜ ìŒì‹ ì¶”ì²œ ì‹œìŠ¤í…œ")
st.markdown("#### ì˜¤ëŠ˜ ë‚ ì”¨ì— ê°€ì¥ ì¸ê¸° ìˆì„ ìŒì‹ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")

encoders, scalers = load_preprocessors()
models = load_models()
df_food = load_food_data()

col1, col2 = st.columns(2)
with col1:
    gender = st.selectbox("ğŸ‘¤ ì„±ë³„", encoders["gender"].classes_)
    age_group = st.selectbox("ğŸ‚ ì—°ë ¹ëŒ€", encoders["age_group"].classes_)
with col2:
    region = st.selectbox("ğŸ“ ì§€ì—­", list(region_coords.keys()))

if st.button("ğŸ” ì¶”ì²œë°›ê¸°"):
    weather = get_weather_data(region)
    st.info(f"ğŸ“¡ '{region}' ì§€ì—­ ë‚ ì”¨: {weather}")
    X = preprocess_input(gender, age_group, region, weather, encoders, scalers)

    scores = {}
    for group, model in models.items():
        try:
            scores[group] = model.predict(X)[0]
        except:
            st.error(f"âŒ {group} ì˜ˆì¸¡ ì‹¤íŒ¨")

    if scores:
        best_group = max(scores, key=scores.get)
        category_map = {
            "BrunchSalad": "ë¸ŒëŸ°ì¹˜/ìƒëŸ¬ë“œ", "Noodles": "ë©´ ìš”ë¦¬", "RiceDishes": "ë°¥/ì£½/ë®ë°¥",
            "SideDish": "ë°˜ì°¬ë¥˜", "SoupStew": "ì°Œê°œ/êµ­/íƒ•", "StirFryGrill": "ë³¶ìŒ/êµ¬ì´"
        }
        korean_group = category_map[best_group]
        st.success(f"ğŸ² ì˜¤ëŠ˜ì€ '{korean_group}'ì´ ê°€ì¥ ì¸ê¸° ìˆì„ ê²ƒ ê°™ì•„ìš”!")

        # ìŒì‹ ì¶”ì²œ
        food_list = df_food[df_food["CKG_GROUP"] == korean_group]["CKG_NM"].dropna().unique()
        if len(food_list) > 0:
            st.markdown("#### ğŸ¥¢ ì¶”ì²œ ìŒì‹:")
            for food in np.random.choice(food_list, size=min(5, len(food_list)), replace=False):
                st.markdown(f"- {food}")

        st.bar_chart(pd.Series(scores).sort_values(ascending=False))

